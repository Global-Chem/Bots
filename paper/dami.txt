Neural Networks possess a distinctive capability to identify relationships and detect patterns within datasets. 
Among these is the Reinforce Neural Network, which distinguishes itself by undergoing a process called reinforcement learning, wherein it is retrained with fresh information provided by users. In the vast expanse of chemical spaces, comprising an astonishing magnitude of up to 10^60 molecules, the potential for discovering novel compounds, distinct from those linked by Structure-Activity Relationships (SARs), becomes a distinct possibility. This Reinforce Neural Network consists of two interconnected networks: the Prior Network and the Agent Network.
The Prior Network is aptly named, having been initially trained to comprehend the intricate patterns and structural configurations of molecules. 
Subsequently, the Agent Network endeavors to generate new compounds. It begins by ascertaining the validity of a generated molecule, utilizing the RDKIT module for verification, followed by an evaluation of its similarity to the chemical repository through the Tanimoto fingerprint similarity.
In an endeavor to enhance this model's efficacy, a strategic decision has been made to incorporate user input into the requisite SMILES (Simplified Molecular Input Line Entry System) list of interest. This augmentation serves the purpose of empowering the model by retraining it to craft novel compounds based on the infusion of novel information, thereby broadening its capacity to innovate and contribute to the discovery of novel chemical entities.

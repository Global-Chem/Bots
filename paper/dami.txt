#New

SMILES is a chemical symbolic representation of molecules into their 1-D string. It's developed in such a way that the characters and letters are intuitive for a chemist to write manually. In realm of artifical intelligence, Recurrent Neural Networks (RNNs) have been developed for language translation (https://www.mdpi.com/2813-2203/2/2/22) and later on was applied to chemistry by Segler et al. (Ref). REINVENT, a specialized RNN, encompasses two interconnected networks: A Prior and an Agent. The Prior intial learning is dependent on an enumerated chemical list provided as the initial vocabulary. In our software, each channel is it's own respective policy based on common chemical lists assigned to a specific category (Global-Chem Ref). When a user intiates an action the agent then generates compounds on 100 step cycle and outputs the image of the molecular list to the user interface. The Agent predicts the next letter of a sequence based on likelihood of what the ajacent letter is based on what is has seen before. Each Agent is based on the Prior's initial learning, to incorporate feedback into our network we implemented a human-assisted intuition feedback loop where users can add or remove SMILES per different categories. Retraining is commenced once a week allowing for an open source forum to naturally develop where the community decide the initial policies to guide the training. 

#stop new

Neural Networks possess a distinctive capability to identify relationships and detect patterns within datasets. 

# Start off with a Recurent Neural Network - 

    1.) how does it learn from languages with letters and words. 
    2.) who did it? Look at the REINVENT paper and find out who did it first with SMILES. What did they say from their abstract. 

# Lets begin now with REINVENT. 

 two interconnected networks: the Prior Network and the Agent Network # Good words

"The Prior Network is aptly named, having been initially trained to comprehend the intricate patterns and structural configurations of molecules."
Not really. Go deeper into 1 and 2.

    1.) Explain how the Prior network is a RL-policy based method. How is it initially trained?
    2.) How does a network generate the next letter in a sequence. Hint using probability?
    3.) Explain how an Agent is Trained off Chemical Input where the Policy is obtained from the prior and then goes through updates based on chemical list input. Borrow some language and 
        rearrange from REINVENT. 

# Validation

Getting there. It begins by ascertaining the validity of a generated molecule, utilizing the RDKIT module for verification, followed by an evaluation of its similarity to the chemical repository through the Tanimoto fingerprint similarity

A molecule is first validated based on whether the SMILES string is possible. (reference rdkit). 
Then the molecule is selected to be a generative descendent from the chemical list input using the Tanimoto Similarity Score metric. Models are stored in a `private-workers` repository. 

"In an endeavor to enhance this model's efficacy, a strategic decision has been made to incorporate user input into the requisite SMILES (Simplified Molecular Input Line Entry System) list of interest."

To select how different REINVENT networks are trained we implemented commands to control the chemical input and retraining cycles occur on a weekly basis. Users have the option of adding, removing SMILES based on molecules generated by the "Mother Nature". Users can debate in an open source forum on Discord for different categories pertaining to different chemical lists. 

Use the word Intuition somewhere. 


Among these is the Reinforce Neural Network, which distinguishes itself by undergoing a process called reinforcement learning, wherein it is retrained with fresh information provided by users. In the vast expanse of chemical spaces, comprising an astonishing magnitude of up to 10^60 molecules, the potential for discovering novel compounds, distinct from those linked by Structure-Activity Relationships (SARs), becomes a distinct possibility. This Reinforce Neural Network consists of two interconnected networks: the Prior Network and the Agent Network.
The Prior Network is aptly named, having been initially trained to comprehend the intricate patterns and structural configurations of molecules. 
Subsequently, the Agent Network endeavors to generate new compounds. It begins by ascertaining the validity of a generated molecule, utilizing the RDKIT module for verification, followed by an evaluation of its similarity to the chemical repository through the Tanimoto fingerprint similarity.
In an endeavor to enhance this model's efficacy, a strategic decision has been made to incorporate user input into the requisite SMILES (Simplified Molecular Input Line Entry System) list of interest. This augmentation serves the purpose of empowering the model by retraining it to craft novel compounds based on the infusion of novel information, thereby broadening its capacity to innovate and contribute to the discovery of novel chemical entities.
